# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15zVuUYqnzmOFuQOMUD-cRBkrcLSxKvCL
"""

# Install required packages
!pip install pandas numpy scikit-learn nltk textblob joblib -q

# Import libraries
import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from textblob import TextBlob
import joblib

# Download NLTK data
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('omw-1.4', quiet=True)

print("âœ… All libraries imported successfully!")

# Check actual column names in your dataset
print("Available columns in dataset:")
print(df.columns.tolist())
print("\n")
print(df.head())

from google.colab import files

# Upload your CSV file
uploaded = files.upload()

# Load the dataset
df = pd.read_csv("Datasetprojpowerbi.csv")

print("âœ… Dataset loaded successfully!\n")
print(f"Total records: {len(df)}")
print(f"\nColumns: {df.columns.tolist()}")
print(f"\nFirst few rows:\n{df.head()}")

# Check for missing values
print(f"\nMissing values:\n{df.isnull().sum()}")

# Check class distribution
print(f"\nClass distribution:\n{df['Genre'].value_counts()}")

# Initialize tools
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

# Enhanced cleaning function
def clean_text(text):
    # Convert to string and lowercase
    text = str(text).lower()

    # Remove URLs
    text = re.sub(r"http\S+|www\.\S+", "", text)

    # Remove emails
    text = re.sub(r'\S+@\S+', '', text)

    # Remove special characters and digits
    text = re.sub(r"[^a-z\s]", " ", text)

    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()

    # Lemmatize and remove stopwords
    words = [lemmatizer.lemmatize(word) for word in text.split()
             if word not in stop_words and len(word) > 2]

    return ' '.join(words)

# Apply cleaning - using 'Reports' column (capital R)
print("ðŸ”„ Cleaning text data...")
df['clean_text'] = df['Reports'].apply(clean_text)

# Add text length as feature
df['text_length'] = df['clean_text'].apply(lambda x: len(x.split()))

# Remove empty rows after cleaning
original_len = len(df)
df = df[df['clean_text'].str.len() > 0]
removed = original_len - len(df)

print(f"âœ… Text cleaning complete!")
print(f"Removed {removed} empty rows after cleaning")
print(f"Remaining records: {len(df)}")
print(f"\nSample cleaned text:")
print(df[['Reports', 'clean_text']].head())

# Optimized TF-IDF vectorizer
vectorizer = TfidfVectorizer(
    max_features=3000,        # Limit features to top 3000
    ngram_range=(1, 2),       # Unigrams + bigrams
    min_df=2,                 # Ignore terms that appear in less than 2 documents
    max_df=0.8,               # Ignore terms that appear in more than 80% of documents
    sublinear_tf=True         # Apply sublinear scaling
)

# Transform text to TF-IDF features
X_text = vectorizer.fit_transform(df['clean_text'])

# Add text length as additional feature
from scipy.sparse import hstack
X_length = df[['text_length']].values
X = hstack([X_text, X_length])

# Target variable - using 'Genre' column (capital G)
y = df['Genre']

print("âœ… Feature extraction complete!")
print(f"Feature matrix shape: {X.shape}")
print(f"Number of classes: {y.nunique()}")
print(f"\nClass distribution:")
print(y.value_counts())

# Split data (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y  # Maintain class distribution
)

print(f"âœ… Train-test split complete!")
print(f"Training set: {X_train.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")

# Dictionary to store models and their scores
models = {}
scores = {}

print("ðŸ”„ Training multiple models...\n")

# 1. Multinomial Naive Bayes
print("1ï¸âƒ£ Training Multinomial Naive Bayes...")
nb_model = MultinomialNB(alpha=0.1)
nb_model.fit(X_train, y_train)
nb_pred = nb_model.predict(X_test)
nb_score = accuracy_score(y_test, nb_pred)
models['Naive Bayes'] = nb_model
scores['Naive Bayes'] = nb_score
print(f"   Accuracy: {nb_score:.4f}\n")

# 2. Logistic Regression (usually best for text)
print("2ï¸âƒ£ Training Logistic Regression...")
lr_model = LogisticRegression(
    max_iter=1000,
    class_weight='balanced',  # Handle imbalanced classes
    C=1.0,
    random_state=42
)
lr_model.fit(X_train, y_train)
lr_pred = lr_model.predict(X_test)
lr_score = accuracy_score(y_test, lr_pred)
models['Logistic Regression'] = lr_model
scores['Logistic Regression'] = lr_score
print(f"   Accuracy: {lr_score:.4f}\n")

# 3. Linear SVM
print("3ï¸âƒ£ Training Linear SVM...")
svm_model = LinearSVC(
    class_weight='balanced',
    max_iter=2000,
    random_state=42
)
svm_model.fit(X_train, y_train)
svm_pred = svm_model.predict(X_test)
svm_score = accuracy_score(y_test, svm_pred)
models['Linear SVM'] = svm_model
scores['Linear SVM'] = svm_score
print(f"   Accuracy: {svm_score:.4f}\n")

# Find best model
best_model_name = max(scores, key=scores.get)
best_model = models[best_model_name]
best_score = scores[best_model_name]

print("="*50)
print(f"ðŸ† BEST MODEL: {best_model_name}")
print(f"ðŸŽ¯ ACCURACY: {best_score:.4f} ({best_score*100:.2f}%)")
print("="*50)

# Get predictions from best model
if best_model_name == 'Linear SVM':
    y_pred = svm_pred
elif best_model_name == 'Logistic Regression':
    y_pred = lr_pred
else:
    y_pred = nb_pred

print(f"\nðŸ“Š DETAILED EVALUATION FOR {best_model_name}\n")
print("="*60)

# Classification Report
print("\nðŸ“‹ Classification Report:\n")
print(classification_report(y_test, y_pred, zero_division=0))

# Confusion Matrix
print("\nðŸ”¢ Confusion Matrix:\n")
cm = confusion_matrix(y_test, y_pred)
print(cm)

# Per-class accuracy
print("\nðŸ“ˆ Per-Class Accuracy:\n")
class_accuracy = cm.diagonal() / cm.sum(axis=1)
for idx, class_name in enumerate(best_model.classes_):
    print(f"{class_name}: {class_accuracy[idx]:.2%}")

print("ðŸ”„ Fine-tuning best model with GridSearch...")

if best_model_name == 'Logistic Regression':
    param_grid = {
        'C': [0.1, 1, 10],
        'solver': ['liblinear', 'saga']
    }
    grid_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)

elif best_model_name == 'Linear SVM':
    param_grid = {
        'C': [0.1, 1, 10]
    }
    grid_model = LinearSVC(class_weight='balanced', max_iter=2000, random_state=42)

else:  # Naive Bayes
    param_grid = {
        'alpha': [0.01, 0.1, 0.5, 1.0]
    }
    grid_model = MultinomialNB()

# Grid Search
grid_search = GridSearchCV(grid_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best model after tuning
tuned_model = grid_search.best_estimator_
tuned_pred = tuned_model.predict(X_test)
tuned_score = accuracy_score(y_test, tuned_pred)

print(f"\nâœ… Tuning complete!")
print(f"Best parameters: {grid_search.best_params_}")
print(f"Tuned accuracy: {tuned_score:.4f} ({tuned_score*100:.2f}%)")

# Use tuned model if better
if tuned_score > best_score:
    best_model = tuned_model
    best_score = tuned_score
    print(f"\nðŸŽ‰ Improved! New accuracy: {best_score*100:.2f}%")
else:
    print(f"\n Original model performed better. Keeping it.")

def get_sentiment(text):
    score = TextBlob(str(text)).sentiment.polarity
    if score > 0:
        return "Positive"
    elif score < 0:
        return "Negative"
    else:
        return "Neutral"

# Apply sentiment - using 'Reports' column
print("ðŸ”„ Analyzing sentiment...")
df['sentiment'] = df['Reports'].apply(get_sentiment)

print("âœ… Sentiment analysis complete!")
print(f"\nSentiment distribution:")
print(df['sentiment'].value_counts())
print(f"\nSample results:")
print(df[['Reports', 'sentiment']].head(10))

# Save best model and vectorizer
joblib.dump(best_model, 'grievance_model.pkl')
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')

print("âœ… Models saved successfully!")
print(f"   - grievance_model.pkl ({best_model_name})")
print(f"   - tfidf_vectorizer.pkl")
print(f"\nFinal Model Accuracy: {best_score*100:.2f}%")

recommendations = {
    "Academic Support and Resources": [
        "Contact your academic advisor or faculty mentor for assistance.",
        "Check the university's academic resource and support portal.",
        "Attend tutoring or remedial sessions organized by the department.",
        "Submit re-evaluation or feedback forms for academic concerns."
    ],
    "Athletics and sports": [
        "Contact the university sports coordinator or coach.",
        "Report damaged or missing equipment to the sports department.",
        "Join scheduled fitness or sports training programs.",
        "Request support for tournament participation or injury management."
    ],
    "Career opportunities": [
        "Visit the placement or career guidance cell for updates.",
        "Update your resume and profile on the university job portal.",
        "Participate in mock interviews and skill development workshops.",
        "Connect with alumni for mentorship and networking opportunities."
    ],
    "Financial Support": [
        "Visit the finance or scholarship office for assistance.",
        "Check scholarship, refund, or financial aid status online.",
        "Submit required financial documents before the deadline.",
        "Email the finance helpdesk for delayed or missing payments."
    ],
    "Health and Well-being Support": [
        "Visit the campus health center or student counseling unit.",
        "Schedule appointments with medical or mental health professionals.",
        "Join stress management and wellness programs offered by the university.",
        "Report sanitation or hygiene issues to the health and safety team."
    ],
    "International student experiences": [
        "Contact the international student office for visa or document support.",
        "Attend orientation and cultural adaptation workshops.",
        "Join international student support and exchange programs.",
        "Reach out to peer mentors for integration guidance."
    ],
    "Online learning": [
        "Report learning portal or LMS issues to the IT helpdesk.",
        "Check availability of recorded lectures and uploaded resources.",
        "Contact your instructors for missed or inaccessible sessions.",
        "Ensure stable internet connection and compatible learning setup."
    ],
    "Student Affairs": [
        "Reach out to the student grievance redressal cell.",
        "Submit formal complaints through the official university portal.",
        "Participate in student council or feedback sessions.",
        "Follow up with the student affairs office regarding case status."
    ],
    "Housing and Transportation": [
        "Report maintenance or safety issues to the housing department.",
        "Contact hostel or transport coordinators for route or schedule updates.",
        "Submit facility requests through the student service app.",
        "Provide feedback on accommodation or transport quality."
    ],
    "Activities and Travelling": [
        "Coordinate with the student travel office for trip approvals.",
        "Ensure travel documents, permissions, and insurance are completed.",
        "Share itinerary details for official student travel.",
        "Report issues related to event logistics or travel delays."
    ],
    "Food and Cantines": [
        "Report food quality or hygiene concerns to the canteen supervisor.",
        "Submit suggestions via the food feedback system.",
        "Request menu adjustments through student representatives.",
        "Participate in food safety and nutrition awareness sessions."
    ]
}

def recommend_actions(grievance_text):
    # Clean the input text
    cleaned = clean_text(grievance_text)

    # Get text length
    text_len = len(cleaned.split())

    # Vectorize
    vec = vectorizer.transform([cleaned])

    # Add length feature
    from scipy.sparse import hstack
    vec_with_len = hstack([vec, [[text_len]]])

    # Predict
    pred = best_model.predict(vec_with_len)[0]

    # Get probability scores (if available)
    if hasattr(best_model, 'predict_proba'):
        proba = best_model.predict_proba(vec_with_len)[0]
        confidence = max(proba) * 100
        print(f"Predicted Category: {pred} (Confidence: {confidence:.2f}%)\n")
    elif hasattr(best_model, 'decision_function'):
        decision = best_model.decision_function(vec_with_len)[0]
        print(f"Predicted Category: {pred}\n")
    else:
        print(f"Predicted Category: {pred}\n")

    # Show recommendations
    print("Recommended Actions:")
    for r in recommendations.get(pred, ["No specific recommendations available."]):
        print(f"â€¢ {r}")

# Test the system
print("\n" + "="*60)
print("ðŸ§ª TESTING RECOMMENDATION SYSTEM")
print("="*60 + "\n")

test_grievance = "I need help with my course registration and academic planning"
print(f"Input: {test_grievance}\n")
recommend_actions(test_grievance)

# Interactive prediction
print("\n" + "="*60)
print("ðŸ’¬ INTERACTIVE GRIEVANCE CLASSIFICATION")
print("="*60 + "\n")

for i in range(5):  # Test 5 times, then stop
    grievance_input = input("Enter your grievance (or 'quit' to exit): ")

    if grievance_input.lower() == 'quit':
        break

    print("\n" + "-"*60)
    recommend_actions(grievance_input)
    print("-"*60 + "\n")

print("âœ… Testing complete!")